% Encoding: UTF-8

@Article{lakens2013,
  author   = {Daniel Lakens},
  title    = {Calculating and reporting effect sizes to facilitate cumulative science: a practical primer for t-tests and ANOVAs},
  journal  = {Frontiers in Psychology},
  year     = {2013},
  volume   = {4},
  number   = {863},
  month    = nov,
  note     = {doi:10.3389/fpsyg.2013.00863},
  abstract = {Effect sizes are the most important outcome of empirical studies. Most articles on effect sizes highlight their importance to communicate the practical signiﬁcance of results. For scientists themselves, effect sizes are most useful because they facilitate cumulative science. Effect sizes can be used to determine the sample size for follow-up studies, or examining effects across studies. This article aims to provide a practical primer on how to calculate and report effect sizes for t-tests and ANOVA’s such that effect sizes can be used in a-priori power analyses and meta-analyses. Whereas many articles about effect sizes focus on between-subjects designs and address within-subjects designs only brieﬂy, I provide a detailed overview of the similarities and differences between withinand between-subjects designs. I suggest that some research questions in experimental psychology examine inherently intra-individual effects, which makes effect sizes that incorporate the correlation between measures the best summary of the results. Finally, a supplementary spreadsheet is provided to make it as easy as possible for researchers to incorporate effect size calculations into their workﬂow.
},
  file     = {:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/Calculating and reporting effect sizes_Lakens_2013.pdf:PDF},
}

@Book{kline2004,
  title     = {Beyond significance testing: Reforming data analysis methods in behavioral research},
  publisher = {American Psychological Association},
  year      = {2004},
  author    = {Rex B. Kline},
  note      = {http://dx.doi.org/10.1037/10693-000},
  abstract  = {This book is a follow-up to the report of Leland Wilkinson and the Task Force on Statistical Inference (TFSI; 1999) of the American Psychological Association (APA) and the fifth edition of the Publication Manual of the American Psychological Association (APA, 2001). The goals of this book are to (a) review the now-large literature across many different disciplines about shortcomings of statistical tests; (b) explain why these criticisms have sufficient merit to justify change in data-analysis practices; (c) help readers acquire new skills concerning effect size estimation and interval estimation for effect sizes; and (d) review additional alternatives to statistical tests, including bootstrapping and Bayesian statistics. An additional goal is related to the criticism that the most recent Publication Manual calls for change in data analysis practices but does not give examples. Numerous examples with actual research results are presented throughout this volume. This book is written for researchers and students in psychology and related areas who may not have strong quantitative backgrounds. It assumes that the reader has had at least one undergraduate-level course in behavioral science statistics. Each substantive chapter begins with a review of fundamental statistical issues but does not get into the minutia of statistical theory. Exercises with answers for the chapters are also available on the Web site. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
}

@Book{cohen1988,
  title     = {Statistical Power Analysis for the Behavioral Sciences},
  publisher = {Lawrence Erlbaum Associates},
  year      = {1988},
  author    = {Jacob Cohen},
  edition   = {Second},
  isbn      = {0-8058-0283-5},
  file      = {:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/Statistical power analysis for the behavioral sciences_Cohen1988.pdf:PDF},
}

@Article{sawilowsky2003,
  author        = {Shlomo S. Sawilowsky},
  title         = {A Different Future For Social And Behavioral Science Research},
  journal       = {Journal of modern applied statistical methods},
  year          = {2003},
  volume        = {2},
  number        = {1},
  month         = may,
  note          = {DOI: 10.22237/jmasm/1051747860},
  __markedentry = {[bryantcm:4]},
  abstract      = {The dissemination of intervention and treatment outcomes as effect sizes bounded by confidence intervals in
order to think meta-analytically was promoted in a recent article in Educational Researcher. I raise concerns
with unfettered reporting of effect sizes, point out the con in confidence interval, and caution against thinking
meta-analytically. Instead, cataloging effect sizes is recommended for sample size estimation and power
analysis to improve social and behavioral science research.},
  file          = {:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/A Different Future For Social And Behavioral Science Research_Sawilowsky_2003.pdf:PDF},
}

@Article{sawilowsky2009,
  author   = {Shlomo S. Sawilowsky},
  title    = {New Effect Size Rules of Thumb},
  journal  = {Journal of modern applied statistical methods},
  year     = {2009},
  volume   = {8},
  number   = {2},
  month    = nov,
  note     = {10.22237/jmasm/1257035100},
  abstract = {Recommendations to expand Cohen’s (1988) rules of thumb for interpreting effect sizes are given to
include very small, very large, and huge effect sizes. The reasons for the expansion, and implications for
designing Monte Carlo studies, are discussed. },
  file     = {:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/New Effect Size Rules of Thumb_sawilowsky_2009.pdf:PDF},
}

@Article{mcgraw1992,
  author  = {Kenneth O. McGraw, S. P. Wong},
  title   = {A common language effect size statistic},
  journal = {Psychological Bulletin},
  year    = {1992},
  volume  = {111},
  number  = {2},
  pages   = {361-365},
  issn    = {0033-2909},
  note    = {10.1037/0033-2909.111.2.361},
  file    = {:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/The common language effect size statistic_McGraw_Wong_1992.pdf:PDF;:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/The common language effect size statistic_McGraw_Wong_1992.pdf:PDF},
}

@Book{rosenthal1991,
  title     = {Meta-Analytic Procedures for Social Research},
  publisher = {SAGE Publications, Inc},
  year      = {1991},
  author    = {Robert Rosenthal},
  editor    = {Michelle R. Starika},
  volume    = {6},
  series    = {Applied social research methods series},
  month     = jan,
  isbn      = {9781412984997},
  note      = {http://dx.doi.org/10.4135/9781412984997},
}

@Article{lalongo2016,
  author  = {Cristiano Lalongo},
  title   = {Understanding the effect size and its measures},
  journal = {Biochemia Medica},
  year    = {2016},
  volume  = {26},
  number  = {2},
  pages   = {150-163},
  month   = jun,
  note    = {10.11613/BM.2016.015},
  file    = {:C\:/Users/bryantcm/Documents/Misc/ResearchPy/Documentation_researchpy/Citation sources/Understandinf the effect size and its measures_lalongo_2016.pdf:PDF},
}

@InBook{hedges1985,
  chapter   = {Statistical Methods in Meta-Analysis},
  title     = {Journal of Educational Statistics},
  publisher = {Academic Press, Inc.},
  year      = {1985},
  author    = {Hedges, Larry and Olkin, Ingram},
  volume    = {20},
  note      = {10.2307/1164953},
}

@InBook{rosenthal1994,
  chapter   = {Parametric measures of effect size},
  pages     = {231-244},
  title     = {The hand-book of research synthesis},
  publisher = {New York, NY: Russel Sage Foundation},
  year      = {1994},
  author    = {Robert Rosenthal},
  editor    = {H. Cooper, L. Hedges},
}

@Comment{jabref-meta: databaseType:bibtex;}
